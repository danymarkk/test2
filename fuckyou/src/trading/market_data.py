"""
PRODUCTION-GRADE MARKET DATA HANDLER
Bulletproof data fetching with retry logic, validation, and caching
"""

import ccxt
import pandas as pd
import numpy as np
from typing import Optional, Tuple, Dict, List
from datetime import datetime, timedelta
import time
import threading
import logging
from dataclasses import dataclass

logger = logging.getLogger(__name__)


class MarketDataError(Exception):
    """Raised when market data operations fail"""
    pass


@dataclass
class MarketDataCache:
    """Cache entry for market data"""
    data: pd.DataFrame
    timestamp: float
    ttl: float


class MarketDataProvider:
    """
    Professional market data provider with institutional-grade reliability
    
    Features:
    - Connection pooling and retry logic
    - Data validation and cleaning
    - Intelligent caching
    - Rate limit management
    - Failover capabilities
    """
    
    def __init__(self, exchange_id: str = 'binance', sandbox: bool = False):
        """
        Initialize market data provider
        
        Args:
            exchange_id: Exchange identifier (binance, bybit, etc.)
            sandbox: Use sandbox/testnet if available
        """
        self.exchange_id = exchange_id
        self.sandbox = sandbox
        
        # Initialize exchange connection
        self._exchange = self._create_exchange()
        
        # Data caching
        self._cache: Dict[str, MarketDataCache] = {}
        self._cache_lock = threading.Lock()
        
        # Rate limiting
        self._last_request_time = 0.0
        self._request_lock = threading.Lock()
        
        # Connection health
        self._connection_healthy = True
        self._last_health_check = 0.0
        
        logger.info(f"Market data provider initialized: {exchange_id}")
    
    def _create_exchange(self) -> ccxt.Exchange:
        """Create and configure exchange connection"""
        try:
            if self.exchange_id == 'binance':
                exchange = ccxt.binance({
                    'apiKey': '',  # Not needed for public data
                    'secret': '',
                    'sandbox': False,  # Always use mainnet for public data - critical fix
                    'enableRateLimit': True,
                    'timeout': 10000,  # 10 second timeout
                    'options': {
                        'defaultType': 'spot',
                        'recvWindow': 10000,
                        'adjustForTimeDifference': True  # Handle clock sync issues
                    },
                    'rateLimit': 100,  # Conservative rate limiting
                    'test': False  # Explicitly disable test mode
                })
            else:
                raise MarketDataError(f"Unsupported exchange: {self.exchange_id}")
                
            # Test connection
            exchange.load_markets()
            logger.info(f"Successfully connected to {self.exchange_id}")
            
            return exchange
            
        except Exception as e:
            raise MarketDataError(f"Failed to connect to {self.exchange_id}: {str(e)}")
    
    def _rate_limit_check(self):
        """Ensure we respect rate limits"""
        with self._request_lock:
            current_time = time.time()
            time_since_last = current_time - self._last_request_time
            min_interval = self._exchange.rateLimit / 1000.0  # Convert to seconds
            
            if time_since_last < min_interval:
                sleep_time = min_interval - time_since_last
                time.sleep(sleep_time)
                
            self._last_request_time = time.time()
    
    def _health_check(self) -> bool:
        """Check exchange connection health"""
        try:
            current_time = time.time()
            
            # Only check every 60 seconds
            if current_time - self._last_health_check < 60:
                return self._connection_healthy
                
            self._last_health_check = current_time
            
            # Simple health check - get server time
            server_time = self._exchange.fetch_time()
            if server_time:
                self._connection_healthy = True
            else:
                self._connection_healthy = False
                
            return self._connection_healthy
            
        except Exception as e:
            logger.warning(f"Health check failed: {e}")
            self._connection_healthy = False
            return False
    
    def _validate_ohlcv_data(self, data: List, symbol: str) -> bool:
        """Validate OHLCV data integrity"""
        try:
            if not data or len(data) == 0:
                logger.warning(f"Empty OHLCV data for {symbol}")
                return False
                
            # Check data structure
            for candle in data[-5:]:  # Check last 5 candles
                if not candle or len(candle) < 6:
                    logger.warning(f"Invalid candle structure for {symbol}")
                    return False
                    
                timestamp, open_price, high, low, close, volume = candle[:6]
                
                # Basic OHLC validation
                if not all(isinstance(x, (int, float)) and x >= 0 for x in [open_price, high, low, close, volume]):
                    logger.warning(f"Invalid OHLC values for {symbol}")
                    return False
                    
                if high < low or high < open_price or high < close or low > open_price or low > close:
                    logger.warning(f"Invalid OHLC relationships for {symbol}: O={open_price}, H={high}, L={low}, C={close}")
                    return False
                    
            return True
            
        except Exception as e:
            logger.error(f"OHLCV validation failed for {symbol}: {e}")
            return False
    
    def _clean_ohlcv_data(self, df: pd.DataFrame, symbol: str) -> pd.DataFrame:
        """Clean and standardize OHLCV data"""
        try:
            df = df.copy()
            
            # Convert timestamp to datetime
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
            
            # Ensure numeric types
            numeric_cols = ['open', 'high', 'low', 'close', 'volume']
            for col in numeric_cols:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # Remove rows with NaN values
            initial_len = len(df)
            df = df.dropna()
            if len(df) < initial_len:
                logger.warning(f"Removed {initial_len - len(df)} invalid rows from {symbol}")
            
            # Sort by timestamp
            df = df.sort_values('timestamp').reset_index(drop=True)
            
            # Remove duplicate timestamps
            initial_len = len(df)
            df = df.drop_duplicates(subset=['timestamp'], keep='last')
            if len(df) < initial_len:
                logger.warning(f"Removed {initial_len - len(df)} duplicate timestamps from {symbol}")
            
            # Final validation
            if len(df) == 0:
                raise MarketDataError(f"No valid data remaining for {symbol}")
                
            return df
            
        except Exception as e:
            raise MarketDataError(f"Data cleaning failed for {symbol}: {str(e)}")
    
    def _get_cache_key(self, symbol: str, timeframe: str, limit: int) -> str:
        """Generate cache key"""
        return f"{symbol}_{timeframe}_{limit}"
    
    def _is_cache_valid(self, cache_entry: MarketDataCache) -> bool:
        """Check if cache entry is still valid"""
        return time.time() - cache_entry.timestamp < cache_entry.ttl
    
    def clear_cache(self):
        """Clear all cached data to force fresh fetches"""
        with self._cache_lock:
            cache_count = len(self._cache)
            self._cache.clear()
        logger.info(f"ðŸ—‘ï¸ Market data cache cleared ({cache_count} entries removed) - forcing fresh data")
    
    def fetch_ohlcv(self, symbol: str, timeframe: str = '1m', limit: int = 100,
                   use_cache: bool = True, cache_ttl: float = 30.0) -> Optional[pd.DataFrame]:
        """
        Fetch OHLCV data with comprehensive error handling
        
        Args:
            symbol: Trading symbol (e.g., 'BTC/USDT')
            timeframe: Candle timeframe ('1m', '5m', '15m', etc.)
            limit: Number of candles to fetch
            use_cache: Whether to use cached data
            cache_ttl: Cache time-to-live in seconds
            
        Returns:
            DataFrame with OHLCV data or None if failed
            
        Raises:
            MarketDataError: If data fetching fails
        """
        try:
            # Check cache first
            if use_cache:
                cache_key = self._get_cache_key(symbol, timeframe, limit)
                with self._cache_lock:
                    if cache_key in self._cache and self._is_cache_valid(self._cache[cache_key]):
                        logger.debug(f"Cache hit for {symbol} {timeframe}")
                        return self._cache[cache_key].data.copy()
            
            # Health check
            if not self._health_check():
                logger.error(f"Exchange unhealthy, cannot fetch data for {symbol}")
                return None
            
            # Rate limiting
            self._rate_limit_check()
            
            # Fetch data with retries
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    logger.debug(f"Fetching {symbol} {timeframe} data (attempt {attempt + 1})")
                    
                    # ðŸš¨ FIX STALE DATA: Force current data - remove since to get latest
                    # For real-time trading, we need the most recent candles
                    ohlcv_data = self._exchange.fetch_ohlcv(symbol, timeframe, limit=limit)
                    
                    # Validate data is recent (within last 10 minutes)
                    if ohlcv_data and len(ohlcv_data) > 0:
                        latest_timestamp = ohlcv_data[-1][0]  # Get timestamp of last candle
                        import datetime
                        current_time = datetime.datetime.now()
                        latest_time = datetime.datetime.fromtimestamp(latest_timestamp / 1000)
                        time_diff = current_time - latest_time
                        
                        if time_diff.total_seconds() > 600:  # More than 10 minutes old
                            logger.warning(f"ðŸš¨ {symbol} data is stale: latest={latest_time}, current={current_time}, diff={time_diff}")
                            # Try to fetch with no cache and small limit for most recent data
                            ohlcv_data = self._exchange.fetch_ohlcv(symbol, timeframe, limit=min(limit, 50))
                    
                    if not self._validate_ohlcv_data(ohlcv_data, symbol):
                        if attempt == max_retries - 1:
                            raise MarketDataError(f"Invalid data for {symbol}")
                        continue
                    
                    # Convert to DataFrame
                    columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
                    df = pd.DataFrame(ohlcv_data, columns=columns)
                    
                    # ðŸš¨ DEBUG: Log timestamp range to detect stale data
                    if not df.empty:
                        oldest_ts = pd.to_datetime(df['timestamp'].min(), unit='ms')
                        newest_ts = pd.to_datetime(df['timestamp'].max(), unit='ms')
                        logger.info(f"ðŸ• {symbol} {timeframe}: Fetched candles from {oldest_ts} to {newest_ts}")
                    
                    # Clean data
                    df = self._clean_ohlcv_data(df, symbol)
                    
                    # Cache the result
                    if use_cache:
                        cache_entry = MarketDataCache(
                            data=df.copy(),
                            timestamp=time.time(),
                            ttl=cache_ttl
                        )
                        with self._cache_lock:
                            self._cache[cache_key] = cache_entry
                    
                    logger.debug(f"Successfully fetched {len(df)} candles for {symbol}")
                    return df
                    
                except ccxt.NetworkError as e:
                    if attempt == max_retries - 1:
                        raise MarketDataError(f"Network error fetching {symbol}: {str(e)}")
                    sleep_time = 2 ** attempt  # Exponential backoff
                    logger.warning(f"Network error for {symbol}, retrying in {sleep_time}s: {e}")
                    time.sleep(sleep_time)
                    
                except ccxt.RateLimitExceeded as e:
                    if attempt == max_retries - 1:
                        raise MarketDataError(f"Rate limit exceeded for {symbol}: {str(e)}")
                    sleep_time = 5 * (attempt + 1)  # Longer backoff for rate limits
                    logger.warning(f"Rate limit hit for {symbol}, sleeping {sleep_time}s")
                    time.sleep(sleep_time)
                    
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise MarketDataError(f"Unexpected error fetching {symbol}: {str(e)}")
                    logger.warning(f"Error fetching {symbol}: {e}")
                    time.sleep(1)
            
            return None
            
        except MarketDataError:
            raise
        except Exception as e:
            raise MarketDataError(f"OHLCV fetch failed for {symbol}: {str(e)}")
    
    def fetch_multiple_timeframes(self, symbol: str, 
                                 timeframes: List[str], 
                                 limit: int = 100) -> Dict[str, Optional[pd.DataFrame]]:
        """
        Fetch multiple timeframes efficiently
        
        Args:
            symbol: Trading symbol
            timeframes: List of timeframes to fetch
            limit: Number of candles per timeframe
            
        Returns:
            Dictionary mapping timeframes to DataFrames
        """
        try:
            results = {}
            
            for timeframe in timeframes:
                try:
                    data = self.fetch_ohlcv(symbol, timeframe, limit)
                    results[timeframe] = data
                    
                    # Small delay between requests
                    time.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"Failed to fetch {symbol} {timeframe}: {e}")
                    results[timeframe] = None
            
            return results
            
        except Exception as e:
            logger.error(f"Multiple timeframe fetch failed: {e}")
            return {}
    
    def get_current_price(self, symbol: str) -> Optional[float]:
        """
        Get current market price
        
        Args:
            symbol: Trading symbol
            
        Returns:
            Current price or None if failed
        """
        try:
            self._rate_limit_check()
            
            ticker = self._exchange.fetch_ticker(symbol)
            if ticker and 'last' in ticker:
                return float(ticker['last'])
            
            return None
            
        except Exception as e:
            logger.error(f"Failed to get current price for {symbol}: {e}")
            return None
    
    def get_symbol_info(self, symbol: str) -> Optional[Dict]:
        """
        Get symbol trading information
        
        Args:
            symbol: Trading symbol
            
        Returns:
            Symbol info dictionary or None if failed
        """
        try:
            markets = self._exchange.load_markets()
            if symbol in markets:
                return markets[symbol]
            
            return None
            
        except Exception as e:
            logger.error(f"Failed to get symbol info for {symbol}: {e}")
            return None
    
    def cleanup_cache(self, max_age: float = 300.0):
        """
        Clean up expired cache entries
        
        Args:
            max_age: Maximum age in seconds for cache entries
        """
        try:
            with self._cache_lock:
                current_time = time.time()
                expired_keys = []
                
                for key, cache_entry in self._cache.items():
                    if current_time - cache_entry.timestamp > max_age:
                        expired_keys.append(key)
                
                for key in expired_keys:
                    del self._cache[key]
                
                if expired_keys:
                    logger.debug(f"Cleaned up {len(expired_keys)} expired cache entries")
                    
        except Exception as e:
            logger.error(f"Cache cleanup failed: {e}")
    
    def get_cache_stats(self) -> Dict:
        """Get cache statistics"""
        try:
            with self._cache_lock:
                total_entries = len(self._cache)
                total_size = sum(len(entry.data) for entry in self._cache.values())
                
                return {
                    'total_entries': total_entries,
                    'total_size': total_size,
                    'cache_keys': list(self._cache.keys())
                }
                
        except Exception as e:
            logger.error(f"Cache stats calculation failed: {e}")
            return {}


# Thread-safe global market data provider instance
_market_data_provider: Optional[MarketDataProvider] = None
_provider_lock = threading.Lock()


def get_market_data_provider(exchange_id: str = 'binance', 
                           sandbox: bool = False) -> MarketDataProvider:
    """
    Get global market data provider instance (thread-safe singleton pattern)
    
    Args:
        exchange_id: Exchange identifier
        sandbox: Use sandbox mode
        
    Returns:
        MarketDataProvider instance
    """
    global _market_data_provider
    
    # Thread-safe double-checked locking pattern
    if _market_data_provider is None:
        with _provider_lock:
            if _market_data_provider is None:  # Double check inside lock
                _market_data_provider = MarketDataProvider(exchange_id, sandbox)
    
    return _market_data_provider


def fetch_ohlcv_data(symbol: str, timeframe: str = '1m', 
                    limit: int = 100) -> Optional[pd.DataFrame]:
    """
    Convenience function to fetch OHLCV data
    
    Args:
        symbol: Trading symbol
        timeframe: Candle timeframe
        limit: Number of candles
        
    Returns:
        DataFrame with OHLCV data or None if failed
    """
    try:
        provider = get_market_data_provider()
        return provider.fetch_ohlcv(symbol, timeframe, limit)
    except Exception as e:
        logger.error(f"Failed to fetch OHLCV data: {e}")
        return None